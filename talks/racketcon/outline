Deconstructing Textuality of Programs
=====================================

When we learn a new programming language,
we are typically presented with its syntax,
that is, the set of rules which allow to transform
text, or a linear string of characters, into
tree-like structures.

Most of you are Lisp programmers, so you're likely
not very interested in knowing syntaxes, because
you use a very simple and effective way of serializing
tree-like structures, commonly known as "s-expressions".

However, s-expressions are still just text.

Well, ok. You're Racketeers, so you can also
include images in your source files, at least
as long as you use DrRacket as your development
environment. But if you save a source file that
contains some images, you're no longer capable
of editing it in, say, Emacs or Vim or Windows
Notepad.

To my knowledge, it is usually also significantly
more difficult to track changes in non-textual
representations of programs, and the common
version control systems aren't well suited to
work with such representations.

My name is Maciek Godek, but I usually present myself
using the nickname "Panicz". I'd like to share with you
the humble results of my research concerning non-textual
approaches to programming, including the ones I've
been pursuing on my own.

But first, I'd like to talk to you a bit about
my motivation: after all, if so many programmers
are satisfied with text as the fundamental representation
of programs, then perhaps it isn't that bad?

I know that the Racket community is rather progressive
when it comes to teaching programming, so some of the
things that I'm going to say are probably going to be
obvious to many of you. But I will say them nevertheless,
because my experience shows that, what I'm about to say,
has been a big revelation to some professional
programmers that I've met along my journey.

Are you ready? So here comes the Big Revelation:

IT IS EASIER FOR US TO UNDERSTAND CONCRETE THINGS
THAN ABSTRACT THINGS.

WE FORM ABSTRACTIONS BY LOOKING AT CONCRETE EXAMPLES.

Why do I think that this revelation is big?

Ok, so, have you ever read any documentation
intended to be read by programers? It usually looks like
this:

blah blah blah blah blah blah blah blah bl-
ah blah blah blah blah blah blah blah blah
... blah blah blah blah blah blah blah blah
blah blah blah blah blah blah blah blah

and then, many scrolls later, there's (sometimes)
a code snippet.

As a programmer, I usually care more about the
code snippet than about the blah blah blah.

When it comes to "code snippets", these also
vary in their scope. Some examples of complicated
C procedures or macros present full working programs.

A fairly common class of example code snippets
scattered around some projects are called 'unit tests'.
Now, that's a bit controversial point. I have seen
projects which contained tests that were completely
unreadable, and were written only to maximize a metric
called 'test coverage'. But let's assume we're dealing
with a well maintained set of tests.

The developers of unit test frameworks for object oriented
languages have distinguished three stages in the life
time of a test: setting up, tearing down and actually
testing whether things are or behave as expected.

Functional programmers further simplify this process:
because pure functions do not depend on any state
or context, they can be tested by simply checking
whether the output of a given function for a given input
matches our expectations.

I have once created a simple unit test framework for
Scheme. The actual implementation is irrelevant, but
the interface is

(e.g. <expression> ===> <result>)

For example (watch out, because I am now going to
present an example of an example!) here are some
definitions of combinatorical functions:

(define (insertions x l)
  (match l
    (`()
     `((,x)))
    (`(,h . ,t)
     `((,x ,h . ,t) . ,(map (lambda (y)
		              `(,h . ,y))
		            (insertions x t))))))
(e.g.
 (insertions 'A '(x y z))
 ===> ((A x y z) (x A y z) (x y A z) (x y z A)))

(define (permutations l)
  (match l
    ('()
     '(()))
    (`(,h . ,t)
     (append-map (lambda (sub)
		   (insertions h sub))
		 (permutations t)))))

(e.g.
 (permutations '(a b c))
 ===> ((a b c) (b a c) (b c a) (a c b) (c a b) (c b a)))

When I look at this code, I start by studying
the examples. Unlike definitions, they are easy
to read and really help to figure out what's
going on, or "what the function is about".
If the example is a good one, it is much more
helpful than a wall of detailed explanations.
I think it's also more valuable than a good name.
Consider this definition:

(define (f lol)
  (apply map list lol))

You are a bunch of sneaky Lisp hackers, so you
probably know what's going on here. But when I show
this example to non-Lisp programmers and tell them
what the functions `map`, `list` and `apply` do,
or even translate this code to Python, they
remain puzzled. However, when I tell them that

(e.g.
  (f '((a b c)
       (d e f)))  ===> ((a d)
                        (b e)
	                (c f)))

they come up with the better name for `f` immediately.

They also realize that the argument is named properly.

So far, I've been trying to convince you about
the immense value of examples, but you probably
already knew it.

So great, let's use examples, then!

I will now show you an example usage function 'g',
and your task is to name this function.

(e.g.
 (g '(0.63+0.27i 0.60+0.87i 0.74+0.92i 0.37+0.81i
      0.30+0.59i 0.94+0.75i 0.56+0.19i 0.52+0.23i
      0.58+0.07i 0.28+0.11i 0.71+0.65i 0.83+0.11i
      0.21+0.95i 0.09+0.56i 0.08+0.43i 0.38+0.48i
      0.10+0.96i 0.64+0.33i 0.49+0.90i 0.63+0.45i
      0.25+0.05i 0.73+0.19i 0.58+0.85i 0.24+0.67i
      0.65+0.25i 0.63+0.42i 0.48+0.46i 0.59+0.40i
      0.97+0.88i 0.81+0.17i 0.14+0.22i 0.83+0.02i
      0.62+0.45i 0.57+0.45i 0.94+0.68i 0.96+0.01i
      0.14+0.74i 0.21+0.36i 0.10+0.60i 0.38+0.55i
      0.68+0.52i 0.37+0.93i 0.27+0.45i 0.05+0.80i
      0.25+0.33i 0.15+0.95i 0.18+0.97i 0.29+0.70i
      0.82+0.45i 0.79+0.50i))
 ===> (0.59+0.4i 0.83+0.11i 0.83+0.02i 0.25+0.05i
       0.14+0.22i 0.08+0.43i 0.05+0.8i 0.1+0.96i
       0.18+0.97i 0.74+0.92i 0.97+0.88i 0.96+0.01i))

Obviously, you can't give me your proposals, because
the talk's been pre-recorded and I cannot get any feedback
from you. But I'd expect the following questions
to show up: "are all the values present in the output
also present in the input?", "if so, are they in the same
order?", "does the order matter?".

Those are of course completely legitimae questions.
But if we just change the way the data is displayed
to show it like this:

[image]

then the intent should become clear.

I believe that this example alone should convince
that text is a fairly limited medium, and that we
should be pushing programming from text towards
programmable visual interactions: that, in addition
to text, we should also be able to present images,
but also videos and also things that can be
interacted with.

Another, lesser known technique of making code
easier to read, perhaps not as ground-breaking,
but still valuable, is the use of prepositions.

The definition

(define (insertions x l) ...)

doesn't make it clear what the roles of subsequent
arguments are. But if we instead write the same
thing as

(define (insertions #;of x #;into l) ...)

the role of arguments becomes immediately clear,
and we're able to pronounce this bit of our code
more smoothly, and to employ the vocal processor in
our brain to facilitate our programming task.

That's all great, but aren't prepositions inherently
textual, and weren't we supposed to be dealing with
non-textuality?

Perhaps the first distincion we need to make
is between text - or the thing we can look at and read
- and speech, which we hear and utter.

"insertions of x into l" makes sense mainly from
the perspective of speech - textually, the prepositions
are redundant.

I have to admit, though, that the area I'd like to
focus the most on is visual programming, so the question
of prepositions was just a minor digression.

It reveals the fact, which often gets ignored
by people involved in the development of "visual
programming environments", that text is also
a visual medium.

However, text seems to be
a privileged representation in the organization
of computer systems. To the point that the phrase
"plain text file" is often associated with
simplicity and minimalism.

We tend to forget, that 'plain text files' usually
reside in some directories, and there are
fairly sophisticated file systems to support this.

I think that the idea of files residing in directories
is an interesting one: computer users usually rely
on their operating system facilities to create
directories and move files around them. Nobody
in the right mind modifies the bytes on their
block device directly, because that could cause
an inconsistency in the file system.

Yet, as programmers, we don't mind being able
to introduce syntax errors to the programs that we
develop, and we seem happy that we can complain
on the poor quality of syntax error messages in some
compilers, and to brag about the exceptional quality
of syntax error messages in other compilers.

Of course, as Lisp programmers you do know, that
there's no real difference between directoties
and s-expressions, and some of you may have 
had an experience in using some structural
editing modes for Emacs.

But still, we tend to think that 'plain text'
is 'the Omega among the turtles', or 'the ultimate
ground'.

To give an example, here's a Quora answer to the question
"Why do we need so many different programming languages?
What's the difference?" from Gerry Rzeppa, the creator
of "Plain English" programming language. The answer has
some tangential points with this talk

<...>

As you can see, he is also concerned with "how
the data is stored on disk".

To be fair, there are approaches which break with
this tradition. One example is the project of the
so called "intentional programming" that was developed
at Microsoft before it was killed in the early 2000s.

It was based on the idea of storing code in a database,
which essentially abstracted from "how the code looks
on the disk". The presentation of code may be different
depending on the contents of a query to the database.

Perhaps the role of IDEs is to treat the set of files
on a disk like a relational database.

The aspect of 'plain text files' which probably
dominates in our thinking is that files are the basic
unit of information exchange. They are 'a single
message' that we can send to someone. And while
we are allowed to put any information we want to
our message, the more assumptions the producer makes
concerning the message, the less likely will they
find someone who'll be able to consume their message.

The most fundamental assumption that is made about
text files, is that it's going to use the ASCII
encoding of bytes, or some its derivative (presumably
UTF8).

Text is a naturally ordered medium, and it is ordered
in at least two senses: first, the alphabet is ordered,
with the order worthy of 27 episodes of Sesame Street;
second, the contents of a file is linearly ordered,
from left to right, from top to the bottom. This order
is so obvious that it may seem not worth mentioning.

But it has consequences that are far from obvious.

A while ago, I have conceived a touch-based interface
to programming. It is based on the idea of nested boxes,
where each box corresponds to a matching pair of
parentheses in a well-formed Lisp code.

That is, unless some special rule is defined for
a particular type of box - then, it could be
visualized or interacted with in some special
way.

However, the ides of 'nesting boxes' allows us
to arrange boxes in a way which makes it unobvious
which box follows after which, like in this example


+-----------+                  +-----------+
|           |     +-------+    |           |
|           |     |       |    |           |
|     A     |     |   B   |    |     C     |
|           |     |       |    |           |
|           |     +-------+    |           |
+-----------+                  +-----------+

This situation is unconceivable in text-based
programming, because all parentheses share
the same size, so we can imagine either

(A) (B) (C)

or

(A) (C) (B)


Moreover, since editing is touch-based, it is
conceivable that the user invents their own symbols.
But it may then be confusing that such symbols
would not belong to any known order.

Another seemingly obvious property of 'plain text'
is that it has structure, or maybe even 'two structures'.
First, text files consist of lines. There are some
essential tools such as 'diff' or 'patch' which rely
on that structure. But there's also a more specific
kind of structure.

We, lisp programmers, sometimes seem to believe
that we're editing abstract syntax tree directly.

But it's rarely the truth: all the code snippets that
I've shown so far, in addition to their 'syntactic
structure', contained some formatting.

One could write this down as

source code = AST + formatting/comments

This means that the relation between source code and
its AST is a homomorphism, that is, there are many
different conceivable source files that correspond
to the same AST.

This relation can be lifted to an isomorphism
if we find a function f:

f(AST) = formatting/comments

The 'pretty-print' function is an example of that,
and so are various auto-formatting tools.

The issue with formatting gets more serious when we
depart from textual representation of the program.
In our example of 'convex-hull', the order of points
was irrelevant. But when we represented the data
as an image, we've lost the capability to express
the order. We could re-gain it by numbering the points,
though, or by drawing arrows between the subsequent
points. Either way, contrary to text/s-expressions,
this representation loses the spatiality of ordering.

The problem is, that we lose the isomorphism between
the visual representation of a structure and its
underlying textual representation.

=====

One undesired consequence of the aforementioned duality
in structures of a text file: the structure stemming
from the 'lines of code' and the structure stemming
from the syntax of a program - is that the 'diffs'
produced between two files can be confusing and
meaningless, and that patches can introduce syntax errors.

Within Lisp communities, there exist several interesting
projects which produce diffs based on tree structures
/s-expressions. One such example is 'autochrome',
developed within the clojure community; another is
ydiff, developed by Yin Wang, a former student
of Kent Dybvig.

Obviously, if we introduce new ways of representing
data, we should be able to express differences
between values in terms of those representations,
which seems to be a non-trivial problem in general,
and as such it should have a fundamental support
from our system.

This is all important to remember, but perhaps
we should also consider another question:
we have seen, how visualizing data can be helpful
and I believe that nobody's questioning that.
But what about visualuzing code? That is, visualizing
in non-textual form?

I don't think that anyone here, seeing a nested box
representation, finds it appealing. Perhaps one could
get used to it over time, but I don't think there's
any point to this: we should be looking for
representations that we find appealing and efficient,
rather than merely workable.

There are of course other visual representations of
code already available, like Scratch or LabView or
flowcharts. But these tend to be domain-specific,
and don't seem to allow arbitrary DSLing.

Perhaps one of the easiest approach in conceiving
a visual notation is to move away from the computer
and to use a pen and a piece of paper and the synthesis
strategy devised in 'Structure and Interpretation of
Computer Programs', namely - wishful thinking.

Let me give you an example of this. Here's an example
piece of code from one approach to designing an editor
based on nesting boxes:

(define (extract #;from box #;at position)
  (let ((hovered unhovered
		 (partition (lambda (child)
			      (is position within?
				  (field #:area child)))
			    (field #:elements box))))
    (match hovered
      ('()
       (values box box))
      (`(,target . ,obscured)
       (let* ((`(,x ,y) position)
	      (`(,l ,t ,r ,b) (field #:area target))
	      (position* `(,(- x l) ,(- y t)))
	      (extracted context
			 (extract #;from target
					 #;at position*)))
	 (if (eq? extracted target)
	     (values target
		     (replace-in box
				 #:elements
				 (union unhovered
					obscured)))
	     (let* ((`(,l* ,t* ,r* ,b*) (field #:area
					       extracted))
		    (area* `(,(- l* l) ,(- t* t)
			     ,(- r* l) ,(- b* t))))
	       (values
		(replace-in extracted #:area area*)
		(replace-in box #:element (union
					   unhovered
					   `(,context)
					   obscured)))))))
      )))

I don't expect you to read this code. I expect you
to feel intimidated.

I can also show you an example, so that you don't
feel any better:

(e.g.
 (let* ((stage
	 (record
	  #:area '(0 0 100 100)
	  #:elements
	  `(,(record
	      #:id 'top-left
	      #:area '(5 5 45 45)
	      #:elements
	      `(,(record #:id 'a #:area '(5 5 15 15)
			 #:elements '())
		,(record #:id 'b #:area '(25 5 35 15)
			 #:elements '())
		,(record #:id 'c #:area '(5 25 15 35)
			 #:elements '())
		,(record #:id 'd #:area '(25 25 35 35)
			 #:elements '())))
	    ,(record #:id 'top-right #:area '(55 5 95 45)
		     #:elements '())
	    ,(record #:id 'bottom-left
 		     #:area '(5 55 45 95) #:elements '())
	    ,(record #:id 'bottom-right
		     #:area '(55 55 95 95)
		     #:elements '()))))
	(extracted leftover
		   (extract stage '(16 16))))
   (values
    (dump extracted)
    (dump leftover)))
 ===>
 (#:area (0 0 10 10) #:elements () #:id a)
 (#:elements
  ((#:elements
    ((#:id b #:area (25 5 35 15) #:elements ())
     (#:id c #:area (5 25 15 35) #:elements ())
     (#:id d #:area (25 25 35 35) #:elements ()))
    #:area (5 5 45 45) #:id top-left)
   (#:id top-right #:area (55 5 95 45) #:elements ())
   (#:id bottom-left #:area (5 55 45 95) #:elements ())
   (#:id bottom-right #:area (55 55 95 95) #:elements ()))
  #:area (0 0 100 100)))

It's a fairly mimimalistic example. It describes
four rectangles, with one of the rectangles containing
four smaller rectangles. You can read that from
indentation and from numbers, or - to say it differently
- you just cannot see that.

I took this code, and translated it to the following
semi-visual pseudocode (it's in Polish, because I am
Polish, sorry)

[image]

But I also translated it to Scheme-style pseudocode,
which should already look fairly straightforward

[image]

The argument box actually represents 'two arguments',
or a compound argument - a position laid over a box.

We consider two cases: when the positiin is over
some inner box, and when there is no inner box at that
position.

In the first case, we call the defined function
recursively, passing the inner box as an argument,
and if it returned the argument repeated twice, then
we return a pair consisting of an inner box and the
ourter box devoid of the inner one.

If it returned something else than the argument repeated
twice, then we return a pair whose first element
is the first element of the value returned, and whose
second element is the original argument, with the
inner box replaced with the second value from
the recursive call.

When no inner box is hovered, then we just return
the original argument repeated twice.

This replication of values is just an ad-hoc convention.
The first value is the box extracted from the context,
and the second value means the context after extraction.

Instead of repeating the same argument twice, we could
as well use some 'nil' value from the second argument.

I don't expect you to getbeverything out of this
explanation, but I hope that you're at least getting
the 'rough idea'.

I have experimented a bit more with this notation,
and rewrore it to a Haskell-inspired style:

[image]

What you may find a bit uncanny is that there are
some names that appear bpyh in patterns and
in the external scope, and that they're meant
to refer to the same thing.

Moreover, the name 'extract', although not misleading,
isn't particularly helpful either: it could mean
just about anything.

So, since we're drawing on paper, we could perhaps
drop textual name in favor of s symbolic one.

I experimented with a funny arrow, which is supposed
to mean 'sucking something out'.

When I did that, I ended up with something that looks
pretty much like a Prolog program.

And even though the notation is very domain-specific,
and even if the domain is fairly small and limited,
I believe it's still worth developing, especially
if it's just a sub-goal of a larger quest, i.e,
a development of general tools for handling visual
notations of different kinds, like Ikea furniture
assembly manuals and other things like that.

Which leads us to the last question, namely the
architecture of a tool that would support such
notations.

It seems like a good idea to require that tool
to store the data in a text-based format, because
that would initially facilitate integration with existing
workflows. This is, for example, what Wolfram's
Mathematica does with its notebooks.

However, the most important trait of such system
would be its self-extensibility. The notable systems
that possess this trait are editors like Emacs
or environments such as Glamorous Toolkit built
on Pharo Smalltalk.

One of the first prototypes of the environment
that I've been working on contained a special form
`define-interaction`, which took a symbol as its first
argument.

(define-interaction (digraph . neighbour-list)
  (Graph neighbour-list))

If that symbol was encountered in a head of some
expression, then instead of following the normal
rules for constructing nested box, it constructed
a special object, according to the given rule.

(define (Graph neighbour-list)
  (let* ((vertices (in-circle
		    (map (lambda (`(,node . ,neigbours))
			   (Vertex node))
			 neighbour-list)))
	 (collection (Collection vertices)))
      (lambda message
	(match message
	  (`(as-image)
	   (let ((image (collection 'as-image)))
	     (for `(,source (,node . ,neighbours))
		 in (zip vertices neighbour-list)
	       (for neighbour in neighbours
		 (let ((target (find (is neighbour eq?
				       (_ 'as-expression))
				vertices)))
		   (draw-edge! source target image))))
	     image))
	  (`(as-expression)
	   `(digraph . ,neighbour-list))
	  
	  (`(acquire-element!)
	   #false)
	  
	  (_
	   (apply collection message))))))

In this case, the extension mechanism assumes that
an expression is a mutable object which reacts in its
own way to events, and which is able to present itself
as an image or as an expression.

While it is a simple and general mechanism, I don't
think it's a good one: it allows the visual
representation to depart from the textual one completely.

I earlier mentioned the "equation":

source code = AST + formatting/comments

where AST is the essential information, and
formatting/comments are things that are related
only to presentation.

I believe that a good design of a versatile
system for programmable interactions would
be a homomorphism:

v(source code) = v1(ast) v2(+) v3(formatting/comments)

For each domain, we also need a 'pretty-print'
function that would work for this particular domain.

Perhaps it would also make sense if all the data
that is interpreted visually could also be interpreted
textually.